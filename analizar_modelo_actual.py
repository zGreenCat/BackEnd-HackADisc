"""
ğŸ“Š ANÃLISIS PROFUNDO DEL MODELO ACTUAL
Genera grÃ¡ficos y mÃ©tricas para entender el comportamiento del modelo hÃ­brido actual
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Configurar estilo de grÃ¡ficos
plt.style.use('default')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

def cargar_modelo_actual():
    """Carga el modelo hÃ­brido actual y sus metadatos"""
    print("ğŸ¤– Cargando modelo hÃ­brido actual...")
    
    try:
        modelo = joblib.load('modelo_hibrido.pkl')
        scaler = joblib.load('scaler_hibrido.pkl')
        metadata = joblib.load('modelo_hibrido_metadata.pkl')
        
        print("âœ… Modelo cargado exitosamente")
        print(f"   ğŸ“… Fecha entrenamiento: {metadata.get('fecha_entrenamiento', 'No disponible')}")
        print(f"   ğŸ¯ MAE: {metadata.get('mae', 'No disponible'):.2f} dÃ­as")
        print(f"   ğŸ“ˆ RÂ²: {metadata.get('r2', 'No disponible'):.4f}")
        print(f"   ğŸ² OOB Score: {metadata.get('oob_score', 'No disponible'):.4f}")
        
        return modelo, scaler, metadata
    except FileNotFoundError as e:
        print(f"âŒ Error: Archivo no encontrado - {e}")
        print("ğŸ’¡ AsegÃºrate de que el modelo estÃ© entrenado y guardado")
        return None, None, None
    except Exception as e:
        print(f"âŒ Error cargando modelo: {e}")
        return None, None, None

def analizar_feature_importance(modelo, metadata):
    """Analiza y visualiza la importancia de features"""
    print("\nğŸ† ANÃLISIS DE IMPORTANCIA DE FEATURES")
    print("=" * 50)
    
    if 'feature_importance' not in metadata:
        print("âŒ No hay datos de importancia de features en el modelo")
        return
    
    # Crear DataFrame de importancia
    importance_df = pd.DataFrame(metadata['feature_importance'])
    
    # Mostrar top 15 features
    print("ğŸ“Š TOP 15 FEATURES MÃS IMPORTANTES:")
    for idx, row in importance_df.head(15).iterrows():
        print(f"   {idx+1:2d}. {row['feature']:25s}: {row['importance']:.4f}")
    
    # GrÃ¡fico de barras - Top 15 features
    plt.figure(figsize=(14, 8))
    top_15 = importance_df.head(15)
    
    bars = plt.barh(range(len(top_15)), top_15['importance'], 
                    color=['#e74c3c' if i == 0 else '#3498db' if i < 5 else '#95a5a6' 
                          for i in range(len(top_15))])
    
    plt.yticks(range(len(top_15)), top_15['feature'])
    plt.xlabel('Importancia')
    plt.title('ğŸ† Top 15 Features MÃ¡s Importantes del Modelo Actual')
    plt.gca().invert_yaxis()
    
    # AÃ±adir valores en las barras
    for i, v in enumerate(top_15['importance']):
        plt.text(v + 0.001, i, f'{v:.3f}', va='center', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('feature_importance_actual.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # GrÃ¡fico circular - DistribuciÃ³n de importancia por categorÃ­as
    plt.figure(figsize=(10, 8))
    
    # Categorizar features
    categorias = {
        'Temporales': ['MesFacturacion', 'AÃ±oFacturacion', 'TrimestreFacturacion', 'DiaSemanaFacturacion', 
                      'TiempoPromedioFacturas', 'DiasInicioAFacturacion'],
        'Financieras': ['ValorVenta', 'MontoPromedioFactura', 'RatioVentaCotizacion', 'StdPagos'],
        'Cliente/Vendedor': ['Cliente_encoded', 'Vendedor_encoded', 'CategoriaPagoCliente'],
        'CaracterÃ­sticas': ['EsSENCE', 'CantidadFacturas', 'CategoriaMontoVenta']
    }
    
    importancia_por_categoria = {}
    for categoria, features in categorias.items():
        total_importancia = importance_df[importance_df['feature'].isin(features)]['importance'].sum()
        importancia_por_categoria[categoria] = total_importancia
    
    plt.pie(importancia_por_categoria.values(), 
            labels=importancia_por_categoria.keys(),
            autopct='%1.1f%%',
            startangle=90,
            colors=['#e74c3c', '#f39c12', '#2ecc71', '#9b59b6'])
    
    plt.title('ğŸ“Š DistribuciÃ³n de Importancia por CategorÃ­a de Features')
    plt.axis('equal')
    plt.savefig('importancia_por_categoria.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return importance_df

def cargar_datos_para_analisis():
    """Carga los datos para anÃ¡lisis de correlaciones"""
    print("\nğŸ“Š Cargando datos para anÃ¡lisis de correlaciones...")
    
    try:
        ventas = pd.read_csv('ventas.csv')
        facturas = pd.read_csv('facturas.csv')
        
        # Convertir fechas
        ventas['FechaInicio'] = pd.to_datetime(ventas['FechaInicio'], errors='coerce')
        facturas['FechaFacturacion'] = pd.to_datetime(facturas['FechaFacturacion'], errors='coerce')
        facturas['FechaEstado'] = pd.to_datetime(facturas['FechaEstado'], errors='coerce')
        
        # Calcular dÃ­as de pago
        pagos_stats = facturas.groupby('idComercializacion').agg({
            'Pagado': ['sum', 'count'],
            'FechaFacturacion': ['min', 'max'],
            'FechaEstado': ['min', 'max']
        }).reset_index()
        
        pagos_stats.columns = ['idComercializacion', 'TotalPagado', 'CantidadFacturas', 
                              'PrimeraFactura', 'UltimaFactura', 'PrimerPago', 'UltimoPago']
        
        pagos_stats['DiasPago'] = (pagos_stats['UltimoPago'] - pagos_stats['PrimeraFactura']).dt.days
        
        # Unir con ventas
        dataset = ventas.merge(pagos_stats, on='idComercializacion', how='inner')
        dataset = dataset[(dataset['DiasPago'] >= 0) & (dataset['DiasPago'] <= 300)].copy()
        
        print(f"âœ… Dataset cargado: {len(dataset):,} registros")
        return dataset
    
    except Exception as e:
        print(f"âŒ Error cargando datos: {e}")
        return None

def analizar_correlaciones(dataset):
    """Analiza correlaciones entre variables y el target"""
    print("\nğŸ”— ANÃLISIS DE CORRELACIONES")
    print("=" * 30)
    
    # Seleccionar variables numÃ©ricas importantes
    vars_numericas = ['ValorVenta', 'ValorCotizacion', 'EsSENCE', 'NumeroEstados', 
                     'CantidadFacturas', 'TotalPagado', 'DiasPago']
    
    # Filtrar solo las que existen
    vars_existentes = [var for var in vars_numericas if var in dataset.columns]
    df_corr = dataset[vars_existentes].copy()
    
    # Calcular matriz de correlaciÃ³n
    correlation_matrix = df_corr.corr()
    
    # GrÃ¡fico de heatmap
    plt.figure(figsize=(12, 10))
    sns.heatmap(correlation_matrix, annot=True, cmap='RdYlBu_r', center=0,
                square=True, linewidths=0.5, fmt='.3f')
    plt.title('ğŸ”— Matriz de Correlaciones - Variables Principales')
    plt.tight_layout()
    plt.savefig('correlaciones_matriz.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # Correlaciones con DiasPago (nuestro target)
    if 'DiasPago' in correlation_matrix.columns:
        correlaciones_target = correlation_matrix['DiasPago'].abs().sort_values(ascending=False)
        
        print("ğŸ¯ CORRELACIONES CON DÃAS DE PAGO (TARGET):")
        for var, corr in correlaciones_target.items():
            if var != 'DiasPago':
                print(f"   {var:20s}: {corr:6.3f}")
        
        # GrÃ¡fico de correlaciones con target
        plt.figure(figsize=(10, 6))
        correlaciones_target_clean = correlaciones_target[correlaciones_target.index != 'DiasPago']
        
        colors = ['#e74c3c' if abs(x) > 0.5 else '#f39c12' if abs(x) > 0.3 else '#3498db' 
                 for x in correlaciones_target_clean.values]
        
        plt.barh(range(len(correlaciones_target_clean)), correlaciones_target_clean.values, color=colors)
        plt.yticks(range(len(correlaciones_target_clean)), correlaciones_target_clean.index)
        plt.xlabel('CorrelaciÃ³n Absoluta con DÃ­as de Pago')
        plt.title('ğŸ¯ Correlaciones con el Target (DÃ­as de Pago)')
        plt.gca().invert_yaxis()
        
        # LÃ­neas de referencia
        plt.axvline(x=0.3, color='orange', linestyle='--', alpha=0.7, label='CorrelaciÃ³n Moderada')
        plt.axvline(x=0.5, color='red', linestyle='--', alpha=0.7, label='CorrelaciÃ³n Fuerte')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('correlaciones_target.png', dpi=300, bbox_inches='tight')
        plt.show()

def analizar_distribucion_target(dataset):
    """Analiza la distribuciÃ³n del target (DiasPago)"""
    print("\nğŸ“ˆ ANÃLISIS DE DISTRIBUCIÃ“N DEL TARGET")
    print("=" * 40)
    
    if 'DiasPago' not in dataset.columns:
        print("âŒ No se encontrÃ³ la columna DiasPago")
        return
    
    dias_pago = dataset['DiasPago'].dropna()
    
    print(f"ğŸ“Š ESTADÃSTICAS DEL TARGET (DiasPago):")
    print(f"   Media: {dias_pago.mean():.2f} dÃ­as")
    print(f"   Mediana: {dias_pago.median():.2f} dÃ­as")
    print(f"   Desv. EstÃ¡ndar: {dias_pago.std():.2f} dÃ­as")
    print(f"   MÃ­nimo: {dias_pago.min():.0f} dÃ­as")
    print(f"   MÃ¡ximo: {dias_pago.max():.0f} dÃ­as")
    print(f"   Q25: {dias_pago.quantile(0.25):.2f} dÃ­as")
    print(f"   Q75: {dias_pago.quantile(0.75):.2f} dÃ­as")
    
    # GrÃ¡fico de distribuciÃ³n
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # Histograma
    axes[0,0].hist(dias_pago, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0,0].axvline(dias_pago.mean(), color='red', linestyle='--', label=f'Media: {dias_pago.mean():.1f}')
    axes[0,0].axvline(dias_pago.median(), color='orange', linestyle='--', label=f'Mediana: {dias_pago.median():.1f}')
    axes[0,0].set_title('ğŸ“Š DistribuciÃ³n de DÃ­as de Pago')
    axes[0,0].set_xlabel('DÃ­as de Pago')
    axes[0,0].set_ylabel('Frecuencia')
    axes[0,0].legend()
    
    # Box plot
    axes[0,1].boxplot(dias_pago, vert=True)
    axes[0,1].set_title('ğŸ“¦ Box Plot - DÃ­as de Pago')
    axes[0,1].set_ylabel('DÃ­as de Pago')
    
    # DistribuciÃ³n por SENCE vs No SENCE
    if 'EsSENCE' in dataset.columns:
        sence_dias = dataset[dataset['EsSENCE'] == 1]['DiasPago'].dropna()
        no_sence_dias = dataset[dataset['EsSENCE'] == 0]['DiasPago'].dropna()
        
        axes[1,0].hist([no_sence_dias, sence_dias], bins=30, alpha=0.7, 
                      label=['No SENCE', 'SENCE'], color=['lightblue', 'lightcoral'])
        axes[1,0].set_title('ğŸ¢ DistribuciÃ³n por Tipo SENCE')
        axes[1,0].set_xlabel('DÃ­as de Pago')
        axes[1,0].set_ylabel('Frecuencia')
        axes[1,0].legend()
        
        print(f"\nğŸ¢ COMPARACIÃ“N SENCE vs NO SENCE:")
        print(f"   No SENCE - Media: {no_sence_dias.mean():.2f} dÃ­as")
        print(f"   SENCE - Media: {sence_dias.mean():.2f} dÃ­as")
        print(f"   Diferencia: {sence_dias.mean() - no_sence_dias.mean():.2f} dÃ­as")
    
    # DistribuciÃ³n por rangos de valor
    if 'ValorVenta' in dataset.columns:
        # Crear categorÃ­as de valor
        dataset['CategoriaValor'] = pd.cut(dataset['ValorVenta'], 
                                         bins=3, labels=['Bajo', 'Medio', 'Alto'])
        
        categorias = ['Bajo', 'Medio', 'Alto']
        datos_por_categoria = [dataset[dataset['CategoriaValor'] == cat]['DiasPago'].dropna() 
                              for cat in categorias]
        
        axes[1,1].boxplot(datos_por_categoria, labels=categorias)
        axes[1,1].set_title('ğŸ’° DÃ­as de Pago por CategorÃ­a de Valor')
        axes[1,1].set_xlabel('CategorÃ­a de Valor de Venta')
        axes[1,1].set_ylabel('DÃ­as de Pago')
    
    plt.tight_layout()
    plt.savefig('analisis_target_distribucion.png', dpi=300, bbox_inches='tight')
    plt.show()

def generar_reporte_completo(modelo, metadata, importance_df, dataset):
    """Genera un reporte completo del anÃ¡lisis"""
    print("\nğŸ“‹ GENERANDO REPORTE COMPLETO")
    print("=" * 30)
    
    reporte = f"""
ğŸ¤– REPORTE DE ANÃLISIS DEL MODELO ACTUAL
{'='*50}

ğŸ“… INFORMACIÃ“N GENERAL:
   â€¢ Fecha de entrenamiento: {metadata.get('fecha_entrenamiento', 'No disponible')}
   â€¢ Casos de entrenamiento: {metadata.get('casos_entrenamiento', 'No disponible'):,}
   â€¢ Casos de test: {metadata.get('casos_test', 'No disponible'):,}

ğŸ“Š MÃ‰TRICAS DEL MODELO:
   â€¢ MAE (Error Absoluto Medio): {metadata.get('mae', 0):.2f} dÃ­as
   â€¢ RÂ² (Coeficiente de DeterminaciÃ³n): {metadata.get('r2', 0):.4f}
   â€¢ RMSE (RaÃ­z Error CuadrÃ¡tico Medio): {metadata.get('rmse', 0):.2f} dÃ­as
   â€¢ OOB Score: {metadata.get('oob_score', 0):.4f}

ğŸ† TOP 5 FEATURES MÃS IMPORTANTES:
"""
    
    for idx, row in importance_df.head(5).iterrows():
        reporte += f"   {idx+1}. {row['feature']}: {row['importance']:.4f}\n"
    
    if dataset is not None and 'DiasPago' in dataset.columns:
        dias_pago = dataset['DiasPago'].dropna()
        reporte += f"""
ğŸ“ˆ ANÃLISIS DEL TARGET:
   â€¢ Media: {dias_pago.mean():.2f} dÃ­as
   â€¢ Mediana: {dias_pago.median():.2f} dÃ­as
   â€¢ DesviaciÃ³n EstÃ¡ndar: {dias_pago.std():.2f} dÃ­as
   â€¢ Rango: {dias_pago.min():.0f} - {dias_pago.max():.0f} dÃ­as
"""
    
    reporte += f"""
ğŸ’¡ RECOMENDACIONES:
   â€¢ El modelo tiene una precisiÃ³n {'BUENA' if metadata.get('r2', 0) > 0.7 else 'MODERADA' if metadata.get('r2', 0) > 0.5 else 'BAJA'}
   â€¢ {'âœ…' if metadata.get('mae', 100) < 15 else 'âš ï¸'} Error promedio: {metadata.get('mae', 0):.2f} dÃ­as
   â€¢ Features temporales {'SÃ' if any('Tiempo' in feat or 'Mes' in feat or 'AÃ±o' in feat for feat in importance_df.head(5)['feature']) else 'NO'} estÃ¡n entre las mÃ¡s importantes
   â€¢ {'Considerar' if metadata.get('r2', 0) < 0.8 else 'No necesario'} re-entrenamiento con features temporales adicionales

ğŸ“ ARCHIVOS GENERADOS:
   â€¢ feature_importance_actual.png
   â€¢ importancia_por_categoria.png
   â€¢ correlaciones_matriz.png
   â€¢ correlaciones_target.png
   â€¢ analisis_target_distribucion.png
   â€¢ reporte_modelo_actual.txt
"""
    
    # Guardar reporte
    with open('reporte_modelo_actual.txt', 'w', encoding='utf-8') as f:
        f.write(reporte)
    
    print(reporte)
    print("âœ… Reporte guardado en: reporte_modelo_actual.txt")

def main():
    """FunciÃ³n principal de anÃ¡lisis"""
    print("ğŸ” ANÃLISIS PROFUNDO DEL MODELO ACTUAL")
    print("=" * 50)
    
    # 1. Cargar modelo
    modelo, scaler, metadata = cargar_modelo_actual()
    if modelo is None:
        return
    
    # 2. Analizar importancia de features
    importance_df = analizar_feature_importance(modelo, metadata)
    if importance_df is None:
        return
    
    # 3. Cargar datos para anÃ¡lisis adicional
    dataset = cargar_datos_para_analisis()
    
    # 4. AnÃ¡lisis de correlaciones
    if dataset is not None:
        analizar_correlaciones(dataset)
        analizar_distribucion_target(dataset)
    
    # 5. Generar reporte completo
    generar_reporte_completo(modelo, metadata, importance_df, dataset)
    
    print("\nğŸ‰ ANÃLISIS COMPLETADO")
    print("ğŸ“Š Revisa los grÃ¡ficos generados para tomar decisiones informadas")
    print("ğŸ“‹ Consulta el reporte completo en: reporte_modelo_actual.txt")

if __name__ == "__main__":
    main()
